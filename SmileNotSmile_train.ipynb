{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Dropout,Flatten,Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 56 #画像の縦横サイズを揃える\n",
    "work_dir = 'archive/lfw-deepfunneled/Smile_NotSmile' #データファイルの置き場\n",
    "npy_data_base = 'Smile_NotSmile-data' #画像データをまとめたファイル名生成用\n",
    "npy_labels_base = 'Smile_NotSmile-labels' #教師データをまとめたファイル名生成用\n",
    "classes = ['Smile','NotSmile'] #分類対象のクラス名\n",
    "num_classes = len(classes) #分類クラス数\n",
    "\n",
    "model_file=\"SmileNotSmile-model-size{0}.hd5\".format(img_size)\n",
    "history_file=\"SmileNotSmile-history-size{0}.csv\".format(img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode=\"train\"\n",
    "npy_data_file=\"{0}/{1}-{2}-w{3}.npy\".format(work_dir,npy_data_base,mode,img_size)\n",
    "npy_labels_file=\"{0}/{1}-{2}-w{3}.npy\".format(work_dir,npy_labels_base,mode,img_size)\n",
    "X_train=np.load(npy_data_file).astype(\"float16\")\n",
    "X_train/=255\n",
    "y_train=np.load(npy_labels_file)\n",
    "y_train=to_categorical(y_train,num_classes)\n",
    "\n",
    "mode=\"test\"\n",
    "npy_data_file=\"{0}/{1}-{2}-w{3}.npy\".format(work_dir,npy_data_base,mode,img_size)\n",
    "npy_labels_file=\"{0}/{1}-{2}-w{3}.npy\".format(work_dir,npy_labels_base,mode,img_size)\n",
    "X_test=np.load(npy_data_file).astype(\"float16\")\n",
    "X_test/=255\n",
    "y_test=np.load(npy_labels_file)\n",
    "y_test=to_categorical(y_test,num_classes)\n",
    "\n",
    "print( X_train.shape )\n",
    "print( y_train.shape )\n",
    "print( X_test.shape )\n",
    "print( y_test.shape )\n",
    "img_rows=X_train.shape[1]\n",
    "img_cols=X_train.shape[2]\n",
    "img_channels=X_train.shape[3]\n",
    "print(\"image_size:\", img_rows, img_cols)\n",
    "print(\"image_channels:\", img_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(img_rows,img_cols,img_channels)\n",
    "model=Sequential()\n",
    "model.add(Conv2D(16, (3,3), activation='relu', padding='same',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(16, (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_epochs=40\n",
    "val_split=0.2\n",
    "batch_size=128\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "cl=CSVLogger(history_file)\n",
    "#fit_log=model.fit(X_train, y_train, batch_size=batch_size,\n",
    "#                  epochs=n_epochs, validation_split=val_split,\n",
    "#                  callbacks=[cl])\n",
    "#if you want to use early stopping, uncomment the following lines\n",
    "es=EarlyStopping(monitor='val_loss',patience=7,verbose=1)\n",
    "fit_log=model.fit(X_train, y_train, batch_size=batch_size,\n",
    "                  epochs=n_epochs, validation_split=val_split,\n",
    "                  callbacks=[cl, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fit_log.history['loss'])\n",
    "plt.plot(fit_log.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train','valid'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(fit_log.history['acc'])\n",
    "plt.plot(fit_log.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train','valid'], loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
